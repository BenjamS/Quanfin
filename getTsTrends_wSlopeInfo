#setwd("D:/OneDrive - CGIAR/Documents")
source('./getTsTrends.R', echo=TRUE)
source('./getGlobTrnds.R', echo=TRUE)
source('./getTsTrends_wSlopeInfo.R')
source('./getTsTrendIndsAndSlope.R')
source('./slopeOsc.R')
source('./collectiveModes.R', echo=TRUE)
library(tidyverse)
library(WaveletComp)
library(quantmod)
library(lubridate)
library(xgboost)
library(caret)
library(pracma)
# library(plyr)
# library(dplyr)
# library(tidyr)
library(FactoMineR)
library(factoextra)
# library(GGally)
# library(cluster)
# library(mclust)
# library(randomForest)
# library(corrplot)
# library(scales)
fromdate<-"2016-01-01"; todate <- "2019-01-01"
getGlobTrnds(fromdate, todate)
#--------------------------------
# Remove obviously incomplete or problematic ts
#rmcol <- which(colnames(cpgtetfmat) %in% c("EXS1.DE", "^IRX", "EWH", "AIA", "XTN", "NLR", "VXX", "PGD", "MIDD", "IWR"))
prob_series <- c("EWH", "AIA", "NLR", "PGD", "IWR", "GRN",
                 "COW", "SGG","BAL", "EWI", "^N225", "EWM",
                 "EGPT", "VXX")
rmcol <- which(colnames(cpgtetfmat) %in% prob_series)
rmcol <- c(rmcol, grep("JJ", colnames(cpgtetfmat)))
xts_cp_mat <- cpgtetfmat[, -rmcol]
xts_vol_mat <- volgtetfmat[, -rmcol]
namevec <- colnames(xts_cp_mat)
n_names <- length(namevec)
#---
# Visually inspect
for(i in 1:n_names){
  df_plot <- fortify(xts_cp_mat[, i])
  this_cp <- colnames(df_plot)[2]
  colnames(df_plot) <- c("Date", "cp")
  gg <- ggplot(df_plot, aes(x = Date, y = cp))
  gg <- gg + geom_line()
  gg <- gg + ggtitle(this_cp)
  print(gg)
  Sys.sleep(2)
}
#--------------------------------
# Remove or replace entries in salvageable ts
o <- apply(xts_cp_mat, 2, function(x) length(which(is.na(x))))
table(o)
rmcols <- which(as.numeric(o) > 60)
colnames(xts_cp_mat)[rmcols]
xts_cp_mat <- xts_cp_mat[, -rmcols]
xts_vol_mat <- xts_vol_mat[, -rmcols]
o <- apply(xts_cp_mat, 1, function(x) length(which(is.na(x))))
table(o)
xts_cp_mat <- na.spline(xts_cp_mat)
xts_vol_mat <- na.spline(xts_vol_mat)
o <- apply(xts_cp_mat, 1, function(x) length(which(is.na(x))))
table(o)
n_ts <- ncol(xts_cp_mat)
#--------------------------------
# Get EMA'd cp mat
#----------------------
per_ema <- 3
#----------------------
xts_cp_ema_mat <- reclass(apply(xts_cp_mat, 2, EMA, per_ema),
                          match.to = xts_cp_mat)
class(xts_cp_ema_mat)
o <- apply(xts_cp_ema_mat, 1, function(x) length(which(is.na(x))))
table(o)
rm_rows <- c(1:(per_ema - 1))
xts_cp_ema_mat <- xts_cp_ema_mat[-rm_rows, ]
o <- apply(xts_cp_ema_mat, 1, function(x) length(which(is.infinite(x))))
table(o)
#--------------------------------
# Get cp slope mat
#----------------------
per_slope <- 3
#----------------------
xts_cp_slope_mat <- reclass(apply(xts_cp_mat, 2, slopeOsc, per_ema, per_slope, programatic_slope = T),
                            match.to = xts_cp_mat)
class(xts_cp_slope_mat)
o <- apply(xts_cp_slope_mat, 1, function(x) length(which(is.na(x))))
table(o)
rm_rows <- c(1:(per_ema + per_slope - 1))
xts_cp_slope_mat <- xts_cp_slope_mat[-rm_rows, ]
o <- apply(xts_cp_slope_mat, 1, function(x) length(which(is.infinite(x))))
table(o)
#--------------------------------
# Get cp slope volatility mat
xts_cp_slopeVolat_mat <- reclass(apply(xts_cp_mat, 2, slopeOsc, per_ema, per_slope, programatic_slopeVolatility = T),
                                 match.to = xts_cp_mat)
class(xts_cp_slopeVolat_mat)
o <- apply(xts_cp_slopeVolat_mat, 1, function(x) length(which(is.na(x))))
table(o)
rm_rows <- c(1:(per_slope + per_ema - 1))
xts_cp_slopeVolat_mat <- xts_cp_slopeVolat_mat[-rm_rows, ]
o <- apply(xts_cp_slopeVolat_mat, 1, function(x) length(which(is.infinite(x))))
table(o)
#--------------------------------
# Get cp detrended mat
xts_cp_detrend_mat <- reclass(apply(xts_cp_mat, 2, slopeOsc, programatic_detrend = T),
                              match.to = xts_cp_mat)
class(xts_cp_detrend_mat)
o <- apply(xts_cp_detrend_mat, 1, function(x) length(which(is.na(x))))
table(o)
rm_rows <- c(1:(per_ema - 1))
xts_cp_detrend_mat <- xts_cp_detrend_mat[-rm_rows, ]
o <- apply(xts_cp_detrend_mat, 1, function(x) length(which(is.infinite(x))))
table(o)
#--------------------------------
# Get smoothed volume
# ^IRX has no volume. Have to get rid of it.
# ^VIX also has no volume, but I think I get the volume for that from VXX
xts_zvol_mat <- reclass(apply(xts_vol_mat, 2, scale), match.to = xts_vol_mat)
class(xts_zvol_mat)
o <- apply(xts_zvol_mat, 1, function(x) length(which(is.na(x))))
table(o)
random_row <- 7
rmcols <- which(is.na(xts_zvol_mat[random_row,]))
which(colnames(xts_zvol_mat) == "^IRX")
colnames(xts_zvol_mat[, rmcols])
print(rmcols)
xts_zvol_mat <- xts_zvol_mat[, -(rm_cols + 1)] #bizarre
colnames(xts_zvol_mat)
o <- apply(xts_zvol_mat, 1, function(x) length(which(is.na(x))))
table(o)
o <- apply(xts_zvol_mat, 1, function(x) length(which(is.nan(x))))
table(o)
o <- apply(xts_zvol_mat, 1, function(x) length(which(is.infinite(x))))
table(o)
#--------------------------------
#Get mean, cv of major groups
df_CV <- fortify(xts_cp_detrend_mat)
this_datevec <- df_CV$Index
df_CV$Index <- NULL
df_CV <- as.data.frame(t(df_CV))
colnames(df_CV) <- as.character(this_datevec)
df_CV$name <- rownames(df_CV)
GroupInfo_raw <- read.csv("GlobTrndsID.csv", stringsAsFactors = F)
GroupInfo_raw$X <- NULL
colnames(GroupInfo_raw)[1] <- "name"
GroupInfo_this <- subset(GroupInfo_raw, !(name %in% prob_series))
#Excluding "groups" with 2 or less ts
rm_these <- names(table(GroupInfo_this$Sub.type)[which(table(GroupInfo_this$Sub.type) <= 2)])
rm_rows <- which(GroupInfo_this$Sub.type %in% rm_these)
GroupInfo_this <- GroupInfo_this[-rm_rows, ]
df_CV <- merge(df_CV, GroupInfo_this[, c("name", "Sub.type")], by = "name")
unique(df_CV$Sub.type)
df_CV$name <- NULL
gathercols <- colnames(df_CV)
df_CVmu <- df_CV %>% group_by(Sub.type) %>% summarise_all(mean)
df_CVsd <- df_CV %>% group_by(Sub.type) %>% summarise_all(sd)
df_groupCV <- as.data.frame(t(df_CVsd[, -1] / df_CVmu[, -1]))
df_groupMU <- as.data.frame(t(df_CVmu[, -1]))
colnames(df_groupCV) <- paste(df_CVmu$Sub.type, "CV")
colnames(df_groupMU) <- paste(df_CVmu$Sub.type, "MU")
#---
o <- apply(df_groupCV, 2, function(x) length(which(is.nan(x))))
table(o)
rmcols <- which(o > 10)
colnames(df_groupCV)[rmcols]
df_groupCV <- df_groupCV[, -rmcols]
df_groupMU <- df_groupMU[, -rmcols]
#---
df_group <- cbind(df_groupCV, df_groupMU)
xts_group <- xts(df_group, as.Date(rownames(df_group)))
#================================
#================================
#================================
# Collective modes analysis
xts_cp_mat_diff <- diff(log(xts_cp_mat))
#xts_cp_mat_diff <- diff(log(xts_cp_mat[-c(1:200), ]))
xts_cp_mat_diff <- xts_cp_mat_diff[-1, ]
datevec <- date(xts_cp_mat_diff)
mat_diff <- xts_cp_mat_diff
rm_these <- setdiff(GroupInfo_raw$name, colnames(xts_cp_mat))
GroupInfo_cm <- GroupInfo_raw[-which(GroupInfo_raw$name %in% rm_these), ]
GroupInfo_cm$Specific.Track <- NULL

out_cm <- collectiveModes(mat_diff, date_vec = datevec, df_group = GroupInfo_cm, 
                          Contrib_as_ModeSq = F,
                          AggregateContributions = F,
                          plot_eigenportfolio_ts = T)
df_sigs <- out_cm[[3]]
u <- colnames(df_sigs)[1:(ncol(df_sigs) - 2)]
colnames(df_sigs)[1:(ncol(df_sigs) - 2)] <- paste("Signal", u)
#---------------------------------
# Plot signals
df_sigs_plot <- df_sigs
gathercols <- colnames(df_sigs_plot)[c(1:(ncol(df_sigs_plot) - 1))]
df_sigs_plot_wide <- df_sigs_plot
df_sigs_plot <- df_sigs_plot %>% gather_("Mode", "Value", gathercols)
#--------------------------------
# df_plot <- subset(df_sigs_plot, Mode %in% c("1", "ts Avg."))
# gg <- ggplot(df_plot, aes(x = Date, y = Value,
#                             group = Mode, color = Mode))
# gg <- gg + geom_line()
# gg
# #--------------------------------
# df_plot <- subset(df_sigs_plot, !(Mode %in% c("1", "5", "6", "ts Avg.")))
# gg <- ggplot(df_plot, aes(x = Date, y = Value,
#                           group = Mode, color = Mode))
# gg <- gg + geom_line()
# gg
#================================
#================================
#================================
# Analyze a specific time series
#--------------------------------
this_ts_name <- "NIB"
#--------------------------------
# Uptrend/Downtrend analysis
# Graphs of cp/ema/slope/slope volatility
# with up/down trends overlaid
#in_ts_cp <- xts_cp_mat[-c(1:200), this_ts_name]
xts_cp <- xts_cp_mat[, this_ts_name]
xts_vol <- xts_vol_mat[, this_ts_name]
#in_ts <- list(in_ts_cp, in_ts_vol)
in_ts <- xts_cp
outlist <- getTsTrends_wSlopeInfo(in_ts, per_ema = 3, per_slope = 3,
                                  thresh_pct_uptrend = 0.75,
                                  thresh_pct_dntrend = -0.75,
                                  graph_on = T,
                                  Periods = NULL)
df_upTrends <- outlist[[1]]
df_dnTrends <- outlist[[2]]
#================================
# Detect periodicity
df_this_ts <- fortify(in_ts)
colnames(df_this_ts)[2] <- "x"
# rmrows <- which(is.na(df_this_ts$x))
# df_this_ts <- df_this_ts[-rmrows, ] 
my.w <- analyze.wavelet(df_this_ts, "x",
                        loess.span = 0,
                        dt = 1, dj = 1/250,
                        lowerPeriod = 2^3,
                        upperPeriod = 2^9,
                        make.pval = TRUE, n.sim = 10)
wt.image(my.w, color.key = "quantile", n.levels = 250,
         legend.params = list(lab = "wavelet power levels", mar = 4.7))
# my.rec <- reconstruct(my.w)
# x.rec <- my.rec$series$x.r  # x: name of original series
df_periodogram <- data.frame(period = my.w$Period, power = my.w$Power.avg)
n_per <- 3
outmat <- findpeaks(df_periodogram$power, nups = 1, ndowns = 1, zero = "0",
                    peakpat = NULL, minpeakheight = 0.05, minpeakdistance = 1, threshold = 0, npeaks = n_per, sortstr = FALSE)
ind_critPoints <- outmat[, 2]
critPoints <- df_periodogram$period[ind_critPoints]
critPoints
gg <- ggplot(df_periodogram, aes(x = period, y = power))
gg <- gg + geom_line()
gg <- gg + geom_vline(xintercept = critPoints, color = "cyan", size = 1.5)
gg
Period_vec <- critPoints
#in_ts_cp <- xts_cp_mat[-c(1:200), this_ts_name]
#in_ts_vol <- xts_vol_mat[, this_ts_name]
#in_ts <- list(in_ts_cp, in_ts_vol)
in_ts <- in_ts_cp
#library(circlize)
outlist <- getTsTrends_wSlopeInfo(in_ts, per_ema = 3, per_slope = 3,
                                  thresh_pct_uptrend = 0.75,
                                  thresh_pct_dntrend = -0.75,
                                  graph_on = T,
                                  Periods = Period_vec)
#================================
# ML model to distinguish false trend starts from real trend starts
# Features
# df_feats <- df_sigs[, c(ncol(df_sigs), 1:(ncol(df_sigs) - 2))]
# df_feats <- df_feats[-1, ]
df_pca <- fortify(xts_zvol_mat)
datevec <- df_pca$Index
df_pca$Index <- NULL
rm_these <- setdiff(GroupInfo_raw$name, colnames(df_pca))
GroupInfo_pca <- GroupInfo_raw[-which(GroupInfo_raw$name %in% rm_these), ]
GroupInfo_pca$Specific.Track <- NULL
df_pca <- as.data.frame(t(df_pca))
colnames(df_pca) <- as.character(datevec)
df_pca$name <- rownames(df_pca)
df_pca <- merge(df_pca, GroupInfo_pca, by = "name")
rownames(df_pca) <- df_pca$name
df_pca$name <- NULL
df_pca$General.Type <- as.factor(df_pca$General.Type)
ind_numeric <- which(!(colnames(df_pca) %in% c("General.Type", "Sub.type", "Specific.Track")))
#----
res <- PCA(df_pca[, ind_numeric])
df_eigenvalues <- as.data.frame(res$eig)
head(df_eigenvalues[, 1:2])
fviz_screeplot(res, ncp = 10)
ind_keep <- which(df_eigenvalues$`percentage of variance` >= 5)
# fviz_pca_biplot(res, habillage = df_pca$General.Type)
fviz_pca_ind(res, col.ind = "cos2")#, habillage = df_pca$General.Type)
fviz_pca_ind(res, habillage = df_pca$General.Type)
df_vol_pc <- as.data.frame(res$var$coord[, ind_keep])
colnames(df_vol_pc) <- paste("Vol", colnames(df_vol_pc))
df_vol_pc$Date <- rownames(df_vol_pc)
#----------------------------------
df_pca <- fortify(xts_cp_slope_mat)
datevec <- df_pca$Index
df_pca$Index <- NULL
rm_these <- setdiff(GroupInfo_raw$name, colnames(df_pca))
GroupInfo_pca <- GroupInfo_raw[-which(GroupInfo_raw$name %in% rm_these), ]
GroupInfo_pca$Specific.Track <- NULL
df_pca <- as.data.frame(t(df_pca))
colnames(df_pca) <- as.character(datevec)
df_pca$name <- rownames(df_pca)
df_pca <- merge(df_pca, GroupInfo_pca, by = "name")
rownames(df_pca) <- df_pca$name
df_pca$name <- NULL
df_pca$General.Type <- as.factor(df_pca$General.Type)
ind_numeric <- which(!(colnames(df_pca) %in% c("General.Type", "Sub.type", "Specific.Track")))
#----
res <- PCA(df_pca[, ind_numeric])
df_eigenvalues <- as.data.frame(res$eig)
head(df_eigenvalues[, 1:2])
fviz_screeplot(res, ncp = 10)
ind_keep <- which(df_eigenvalues$`percentage of variance` >= 5)
# fviz_pca_biplot(res, habillage = df_pca$General.Type)
fviz_pca_ind(res, col.ind = "cos2")#, habillage = df_pca$General.Type)
#fviz_pca_ind(res, habillage = df_pca$General.Type)
df_slope_pc <- as.data.frame(res$var$coord[, ind_keep])
colnames(df_slope_pc) <- paste("Slope", colnames(df_slope_pc))
df_slope_pc$Date <- rownames(df_slope_pc)
#----------------------------------
df_groupCVMU <- fortify(xts_group)
colnames(df_groupCVMU)[1] <- "Date"
df_groupCVMU$Date <- as.character(df_groupCVMU$Date)
list_df_feats <- list(df_groupCVMU, df_slope_pc, df_vol_pc)
df_feats <- join_all(list_df_feats, by = "Date")
o <- apply(df_feats[, -1], 1, function(x) length(which(is.na(x))))
table(o)
rm_rows <- 1:(per_ema + per_slope - 1)
df_feats <- df_feats[-rm_rows, ]
o <- apply(df_feats[, -1], 1, function(x) length(which(is.na(x))))
table(o)
df_feats$Date <- as.Date(df_feats$Date)
#-------------------------
# Predictand
# ind_false <- which(df_dnTrends$`False downtrend` == 1)
# ind_start <- which(df_feats$Date %in% df_dnTrends$DnStartDate[-ind_false])
# ind_stop <- which(df_feats$Date %in% df_dnTrends$DnStopDate[-ind_false])
# ind_falseStart <- which(df_feats$Date %in% df_dnTrends$DnStartDate[ind_false])
# ind_falseStop <- which(df_feats$Date %in% df_dnTrends$DnStopDate[ind_false])
ind_false <- which(df_upTrends$`False uptrend` == 1)
ind_start <- which(df_feats$Date %in% df_upTrends$UpStartDate[-ind_false])
ind_stop <- which(df_feats$Date %in% df_upTrends$UpStopDate[-ind_false])
ind_falseStart <- which(df_feats$Date %in% df_upTrends$UpStartDate[ind_false])
ind_falseStop <- which(df_feats$Date %in% df_upTrends$UpStopDate[ind_false])
# Add some padding to the trend start/stop dates
leeway_before <- 2
leeway_after <- 2
df_ML_in <- df_feats
df_ML_in$y <- "Hold"
# df_ML_in$y[ind_start] <- "Start"
# df_ML_in$y[ind_stop] <- "Stop"
for(i in 1:length(ind_start)){df_ML_in$y[(ind_start[i] - leeway_before):(ind_start[i] + leeway_after)] <- "Start"}
for(i in 1:length(ind_stop)){df_ML_in$y[(ind_stop[i] - leeway_after):(ind_stop[i] + leeway_before)] <- "Stop"}
for(i in 1:length(ind_falseStart)){df_ML_in$y[(ind_falseStart[i] - leeway_before):(ind_falseStart[i] + leeway_after)] <- "False Start"}
for(i in 1:length(ind_falseStop)){df_ML_in$y[(ind_falseStop[i] - leeway_after):(ind_falseStop[i] + leeway_before)] <- "False Stop"}
df_ML_in <- subset(df_ML_in, y %in% c("Start", "False Start"))
featNames <- colnames(df_ML_in)[-ncol(df_ML_in)]
yName <- colnames(df_ML_in)[ncol(df_ML_in)]
df_ML_in$y <- as.factor(df_ML_in$y)
df_ML_date <- df_ML_in$Date
df_ML_in$Date <- NULL
#---------------------
# set.seed(1234)
# splitIndex <- createDataPartition(df_ML_in[, yName], p = .65, list = FALSE, times = 1)
# df_train <- df_ML_in[ splitIndex,]
# df_test <- df_ML_in[-splitIndex,]
trainDat_pctot <- .65
indtrain_beg <- 1
indtrain_end <- round(nrow(df_ML_in) * trainDat_pctot)
indtest_beg <- indtrain_end + 1
indtest_end <- nrow(df_ML_in)
indtrain <- indtrain_beg:indtrain_end
indtest <- indtest_beg:indtest_end
df_train <- df_ML_in[indtrain, ]
df_test <- df_ML_in[indtest, ]

nrow(df_ML_in)
nrow(df_train)
nrow(df_test)

# Before ML, just do a simple linear model
contrasts(df_train$y)
model <- glm(y ~., family = binomial(link = 'logit'), data = df_train)
summary(model)
anova(model, test="Chisq")
fitted.prob <- predict(model, newdata = df_test, type = 'response')
fitted.binry <- ifelse(fitted.prob > 0.6, 1, 0)
df_compare <- data.frame(predicted_prob = fitted.prob, predicted_binry = fitted.binry, observed = df_test$y)
df_compare$observed <- ifelse(df_test$y == "Start", 1, 0)
misClasificError <- mean(df_compare$predicted_binry != df_compare$observed)
print(paste('Accuracy', round(1 - misClasificError, 2)))
misClasificError <- mean(abs(df_compare$observed - df_compare$predicted_prob))
print(paste('Accuracy (prob)', round(misClasificError, 2)))

df_compare$Date <- df_ML_date[indtest]
df_plot <- fortify(xts_cp_mat[, this_ts_name])
colnames(df_plot) <- c("Date", "cp")
df_plot <- left_join(df_plot, df_compare)
indtest_cp <- c(which(df_plot$Date == df_compare$Date[1]):nrow(df_plot))
df_plot <- df_plot[indtest_cp,]
df_plot_up_true <- subset(df_upTrends, `False uptrend` == 0)
df_plot_up_false <- subset(df_upTrends, `False uptrend` == 1)
n_bins <- length(indtest_cp)
df_probGradient <- data.frame(xmin = df_plot$Date[-n_bins], xmax = df_plot$Date[-1])
df_probGradient$predProbs <- df_plot$predicted_prob[-1]
u <- df_probGradient$predProbs
df_probGradient$predProbs[which(is.na(u))] <- 0.5
gg <- ggplot()
gg <- gg + geom_rect(data = df_probGradient, aes(xmin = xmin, xmax = xmax,
                                                 ymin = -Inf, ymax = Inf, fill = predProbs), alpha = 0.7)
gg <- gg + scale_fill_gradient2(low = "darkmagenta", mid = "white", high = "green", midpoint = 0.5)
gg <- gg + geom_line(data = df_plot, aes(x = Date, y = cp))
gg <- gg + theme_bw()
gg <- gg + ggtitle("Backtest: Predicted start in green, false start in red. Shade = confidence.")
gg <- gg + theme(axis.title.x = element_blank(),
                 axis.text.x = element_blank(),
                 axis.ticks.x = element_blank(),
                 axis.title.y = element_blank(),
                 panel.grid.major = element_blank(),
                 panel.grid.minor = element_blank(),
                 legend.position = "none",
                 plot.title = element_text(hjust = 0.5))
gg
gg_predicted <- gg


indtest_trends <- which(df_upTrends$UpStartDate %in% df_plot$Date)
df_upTrends_test <- df_upTrends[indtest_trends,]
gg <- ggplot()
gg <- gg + geom_rect(data = df_upTrends_test, aes(xmin = UpStartDate, xmax = UpStopDate,
                                             ymin = -Inf, ymax = Inf, fill = `Pct. Change/Time`), alpha = 0.7)
gg <- gg + scale_fill_gradient2(low = "darkmagenta", mid = "khaki2", high = "green")
gg <- gg + geom_line(data = df_plot, aes(x = Date, y = cp))
gg <- gg + scale_x_date(date_breaks = "1 month", date_labels = "%b-%Y")
gg <- gg + geom_vline(data = df_plot_up_false, aes(xintercept = UpStartDate), color = "darkmagenta", alpha = 0.4)
gg <- gg + geom_vline(data = df_plot_up_false, aes(xintercept = UpStopDate), color = "darkmagenta", alpha = 0.4)
#gg <- gg + geom_vline(data = df_compare, aes(xintercept = Date), color = "green", size = 0.5, linetype = "dotted")
# gg <- gg + geom_hline(data = df_plot_mean_line, aes(yintercept = mu_line), color = "blue")
# gg <- gg + geom_hline(data = df_plot_sd_lines1, aes(yintercept = sd_line), color = "orange")
# gg <- gg + geom_hline(data = df_plot_sd_lines2, aes(yintercept = sd_line), color = "orange")
gg <- gg + theme_bw()
gg <- gg + ggtitle("Uptrends marked in green, false trends in red. Shade = return intenstity")
gg <- gg + theme(axis.title.x = element_blank(),
                 # axis.text.x = element_blank(),
                 # axis.ticks.x = element_blank(),
                 axis.title.y = element_blank(),
                 panel.grid.major = element_blank(),
                 panel.grid.minor = element_blank(),
                 legend.position = "none",
                 plot.title = element_text(hjust = 0.5))
gg
gg_observed <- gg
#library(gridExtra)
grid.arrange(gg_predicted, gg_observed)


#==================================
#Trading simulator
tradeIt <- function(invest_t0 = 500, Commission = 7, rateRet_vec){
  money <- invest_t0
  money_vec <- c()
  for(i in 1:length(rateRet_vec)){money <- money * (1 + rateRet_vec[i]) - 2 * Commission
  money_vec[i] <- money}
  return(list(money, money_vec))
}
invest_t0 <- 250
Commission <- 7
#Trade on naive uptrends -- strictly follow slope crossings
rateRet_vec <- df_upTrends_test$`Pct. Change` / 100
out <- tradeIt(invest_t0, Commission, rateRet_vec)
NetGain_up_naive <- out[[1]] - invest_t0
trajectory_naive <- out[[2]]
NetGain_up_naive
#Trade on model signals
df_tradeSigs <- df_plot
u <- df_tradeSigs$predicted_prob
df_tradeSigs$predicted_prob[which(is.na(u))] <- 0.5
df_slope <- fortify(xts_cp_slope_mat[, this_ts_name])
colnames(df_slope) <- c("Date", "slope")
df_slope$Date <- as.Date(df_slope$Date)
class(df_slope$Date)
df_tradeSigs <- left_join(df_tradeSigs, df_slope)
tradeStartDates <- c()
tradeStopDates <- c()
trade_rateRet_vec <- c()
cpStart_vec <- c()
cpStop_vec <- c()
t <- 0
trade_on <- F
for(i in 1:nrow(df_tradeSigs)){
  if(trade_on){
    if(abs(df_tradeSigs$slope[i]) < 10^-2){ 
      tradeStopDates[t] <- df_tradeSigs$Date[i]
      cpStop <- df_tradeSigs$cp[i]
      trade_rateRet <- (cpStop - cpStart) / cpStart
      cpStop_vec[t] <- cpStop
      trade_rateRet_vec[t] <- trade_rateRet
      trade_on <- F}
    }else{
      if(df_tradeSigs$predicted_prob[i] > 0.75){
        t <- t + 1
        trade_on <- T
        tradeStartDates[t] <- df_tradeSigs$Date[i]
        cpStart <- df_tradeSigs$cp[i]
        cpStart_vec[t] <- cpStart
      }
      
  }
}
df_tradeJournal <- data.frame(startDate = tradeStartDates, stopDate = tradeStopDates,
                              rateRet = trade_rateRet_vec)

pctRet_vec <- df_tradeJournal$rateRet
out <- tradeIt(invest_t0, Commission, pctRet_vec)
NetGain_up_shrewd <- out[[1]] - invest_t0
trajectory_shrewd <- out[[2]]

df_trade <- df
df_trade$Investment_naive <- NA
df_trade$Investment_naive[which(df$Date %in% df_upTrends$UpStopDate)] <- trajectory_naive
df_trade$Investment_shrewd <- NA
df_trade$Investment_shrewd[which(df$Date %in% df_upTrends$UpStopDate[ind_shrewd])] <- trajectory_shrewd
df_trade$Year <- year(df_trade$Date)
df_trade_up <- df_trade




















#this_method <- "glmnet"
#this_method <- "glm"
#this_method <- "nb"
#this_method <- "gbm" #good
#this_method <- "xgbLinear"
this_method <- "xgbTree" #better
#this_method <- "naive_bayes"
#this_method <- "svmRadial"
#this_method <- "cforest"
#this_method <- "rf"

# gbmGrid <-  expand.grid(n.trees = 50, interaction.depth =  c(1, 5, 9),
#                         shrinkage = 0.01, n.minobsinnode = )
# run model
# head(trainDF[,predictorsNames])
# head(trainDF[,outcomeName])
# head(trainDF)
# params <- list(booster = "gbtree", objective = "multi:softmax", eta = 0.1,
#                gamma = 0, max_depth = 25, min_child_weight = 1, subsample = 0.5,
#                colsample_bytree = 0.5, num_class = 5)
#=============================
#modelLookup(this_method)
#=============================
#number = 5 is better (and slower)
objControl <- trainControl(method = 'repeatedcv', number = 5)#, repeats = 3)
# objControl <- trainControl(
#   method = "repeatedcv",
#   number = 5,
#   repeats = 2,
#   returnData = FALSE,
#   classProbs = TRUE,
#   summaryFunction = multiClassSummary
# )

# df_train$y <- as.factor(make.names(as.character(df_train$y)))
# class(df_train$y)
# df_test$y <- as.factor(make.names(as.character(df_test$y)))

# tune_grid <- expand.grid(nrounds=c(25, 40, 60),
#                         max_depth = c(25),
#                         eta = c(0.05, 0.1, 0.3),
#                         gamma = c(0),
#                         colsample_bytree = c(0.5, 0.75),
#                         subsample = c(0.50),
#                         min_child_weight = c(0))

objModel <- train(df_train[, featNames], df_train[, yName],
                  method = this_method,
                  trControl = objControl)
#-----------------------------
var_importance <- varImp(objModel, scale = T)
print(var_importance)
#plot(var_importance)
#-----------------------------
#Predict using fitted model
# probabilities ("prob") or integer ("raw")
predictions <- predict(object = objModel, df_test[, featNames], type = "raw")#type = 'raw') #type='prob')
print(postResample(pred = predictions, obs = as.factor(df_test[, yName])))
#head(predictions)
#df_plot <- rownames(df_test)
# df_eval <- df_ML_in
# df_eval$Date <- df_feats$Date
# df_cp <- fortify(xts_cp)
# colnames(df_cp) <- c("Date", "cp")
# df_eval <- merge(df_eval, df_cp, by = "Date")
# df_eval$yPred <- NA
# df_eval$yPred[indtest_beg:indtest_end] <- as.character(predictions)
# ind_predStart <- which(df_eval$yPred == "Start")
# ind_predStop <- which(df_eval$yPred == "Stop")
# predDuration <- ind_predStop - ind_predStart
# predPctChng <- df_eval$cp[ind_predStop] - df_eval$cp[ind_predStop]
# predPctChngperTime <- predPctChng / predDuration
# predStartDate <- df_eval$Date[ind_predStart]
# predStopDate <- df_eval$Date[ind_predStop]
# df_predTrends <- data.frame(predStartDate, predStopDate, predPctChngperTime)
# gg <- ggplot()
# gg <- gg + geom_rect(data = df_predTrends, aes(xmin = prednStartDate, xmax = predStopDate,
#                                              ymin = -Inf, ymax = Inf, fill = predPctChngperTime), alpha = 0.7)
# gg <- gg + scale_fill_gradient2(low = "green", mid = "khaki2", high = "darkmagenta")
# gg <- gg + geom_line(data = df_eval, aes(x = Date, y = cp))
# gg
#----------------------------
#Confusion matrix
x <- confusionMatrix(predictions, df_test[, yName])
confmat <- x$table
confmat <- round(confmat %*% solve(diag(colSums(confmat))), 3)
confmat <- as.table(confmat)
colnames(confmat) <- rownames(confmat)
names(dimnames(confmat))[2] <- "Reference"
print(confmat)
print(x$table)
class(confmat)
df_plot <- as.data.frame(confmat)
gg <- ggplot(df_plot) + geom_tile(aes(x = Prediction, y = Reference, fill = Freq))
gg <- gg + scale_fill_gradient(low = "orange", high = "cyan")
gg
#---------------------

#================================
# Baysean VAR
library(devtools)
install_github("gabrielrvsc/HDeconometrics")
# = load package and data = #
library(HDeconometrics)
data("voldata")

# = Break data into in and out of sample to test model accuracy= #
Yin = voldata[1:5499,]
Yout = voldata[-c(1:5499),]
# = Run models = #
# = OLS = #
# modelols = HDvar(Yin,p=22) # takes a while to run
# predols = predict(modelols,h=22)
# = BVAR = #
modelbvar = lbvar(Yin, p = 22, delta = 0.5)
predbvar = predict(modelbvar, h = 22)
# = Forecast
k="KO"
plot(tail(voldata[, k], 122), type = "l", main = "forecasts")
lines(c(rep(NA, 100), predols[, k]), col = 2)
lines(c(rep(NA, 100), predbvar[, k]), col = 4)
abline(v = 100, lty = 2, col = 4)
legend("topleft",legend=c("OLS","BVAR"),col=c(2,4),lty=1,lwd=1,seg.len=1,cex=1,bty="n")
# = Overall percentual error = #
MAPEols=abs((Yout-predols)/Yout)*100
MAPEbvar=abs((Yout-predbvar)/Yout)*100
matplot(MAPEols,type="l",ylim=c(0,80),main="Overall % error",col="lightsalmon",ylab="Error %")
aux=apply(MAPEbvar,2,lines,col="lightskyblue1")
lines(rowMeans(MAPEols),lwd=3,col=2,type="b")
lines(rowMeans(MAPEbvar),lwd=3,col=4,type="b")
legend("topleft",legend=c("OLS","BVAR"),col=c(2,4),lty=1,lwd=1,seg.len=1,cex=1,bty="n")
# = Influences = #
aux=modelbvar$coef.by.block[2:23]
impacts=abs(Reduce("+", aux ))
diag(impacts)=0
I=colSums(impacts)
R=rowSums(impacts)
par(mfrow=c(2,1))
barplot(I,col=rainbow(30),cex.names = 0.3, main = "Most Influent")
barplot(R,col=rainbow(30),cex.names = 0.3, main = "Most Influenced")

















# require(graphics)
# ## Non-Seasonal Holt-Winters
# x <- df_ts$ts_ema
# m <- HoltWinters(x, gamma = FALSE)
# plot(m)
# #plot(fitted(m))
# ## Exponential Smoothing
# m2 <- HoltWinters(x, gamma = FALSE, beta = FALSE)
# lines(fitted(m2)[,1], col = 3)
